{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import torch\n",
    "torch.manual_seed(0) # set random seed\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from ddpg_agent_p2 import Agent # load Agent from ddpg_agent_p2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='E:/code/deep-reinforcement-learning/p2_continuous-control/Reacher_Windows_x86_64_v2/Reacher.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=1000, max_t=1000, print_every=10, average_every=100):\n",
    "    \"\"\"The interface that calls ddpg agent and env\n",
    "    Params\n",
    "    ======\n",
    "      n_episode (int): total number episode to run\n",
    "      max_t (int): max number of time steps in one episode\n",
    "      print_every: print the average score of agents and episodes every episode interval\n",
    "      average_every: take the average score of agents and episodes over the lat average_every episodes\n",
    "    \"\"\"\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    num_agents = len(env_info.agents)\n",
    "    a_size = brain.vector_action_space_size\n",
    "    s_size = env_info.vector_observations.shape[1]\n",
    "    \n",
    "    agent = Agent(state_size=s_size, action_size=a_size, random_seed=2) # create agent\n",
    "    \n",
    "    scores_history = [] # store the average scores of arms over episodes\n",
    "    scores_deque = deque(maxlen = average_every) # store the recent average scores\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations # get initial states of arms\n",
    "        agent.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        start_time = time.time()\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            # save the tuples of arms in the agent's buffer\n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done, t)\n",
    "                        \n",
    "            scores += rewards\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        \n",
    "        run_time = time.time() - start_time\n",
    "        scores_deque.append(np.mean(scores))\n",
    "        scores_history.append(np.mean(scores))\n",
    "        print('\\rEpisode {}\\tScore: {:.2f}\\tRuntime: {:.2f} sec'.format(i_episode, np.mean(scores), run_time))\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque) >= 30:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "        \n",
    "    return scores_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent constructor is called\n",
      "Episode 1\tScore: 21.76\tRuntime: 5.71 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = ddpg(n_episodes=1)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent constructor is called\n",
      "Total score: 36.342499187681824\n"
     ]
    }
   ],
   "source": [
    "# watch the performance of the trained agent\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "\n",
    "num_agents = len(env_info.agents)\n",
    "a_size = brain.vector_action_space_size\n",
    "s_size = env_info.vector_observations.shape[1]\n",
    "\n",
    "agent = Agent(state_size=s_size, action_size=a_size, random_seed=2)\n",
    "\n",
    "# load the saved weights into the agent\n",
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth'))\n",
    "\n",
    "states = env_info.vector_observations   # get initial states\n",
    "scores = np.zeros(num_agents)\n",
    "\n",
    "while True:\n",
    "    actions = agent.act(states, add_noise=False)                 # get actions over arms\n",
    "    env_info = env.step(actions)[brain_name]    # take actions for arms\n",
    "    next_states = env_info.vector_observations  # get new states of arms\n",
    "    rewards = env_info.rewards                  # get rewards\n",
    "    dones = env_info.local_done                 # get done signals\n",
    "    scores += env_info.rewards                  # accumulate scores\n",
    "    states = next_states                        # update states\n",
    "    if np.any(dones):\n",
    "        break\n",
    "print('Total score: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
