{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import torch\n",
    "torch.manual_seed(0) # set random seed\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "from ddpg_agent_p2 import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='E:/code/deep-reinforcement-learning/p2_continuous-control/Reacher_Windows_x86_64/Reacher.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# num_agents = len(env_info.agents)\n",
    "# action_size = brain.vector_action_space_size\n",
    "# state_size = env_info.vector_observations.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ddpg(n_episodes=1000, max_t=1000, print_every=10, average_every=100):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    num_agents = len(env_info.agents)\n",
    "    a_size = brain.vector_action_space_size\n",
    "    s_size = env_info.vector_observations.shape[1]\n",
    "    \n",
    "    agent = Agent(state_size=s_size, action_size=a_size, random_seed=2)\n",
    "    \n",
    "    scores_history = []\n",
    "    scores_deque = deque(maxlen = average_every)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        scores = np.zeros(num_agents)\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            \n",
    "            for state, action, reward, next_state, done in zip(states, actions, rewards, next_states, dones):\n",
    "                agent.step(state, action, reward, next_state, done)\n",
    "                        \n",
    "            scores += rewards\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        \n",
    "        run_time = time.time() - start_time\n",
    "        scores_deque.append(np.mean(scores))\n",
    "        scores_history.append(np.mean(scores))\n",
    "        print('\\rEpisode {}\\tScore: {:.2f}\\tRuntime: {:.2f} sec'.format(i_episode, np.mean(scores), run_time))\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "        if np.mean(scores_deque) >= 30:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_deque)))\n",
    "            torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "        \n",
    "    return scores_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tScore: 0.00\tRuntime: 16.82 sec\n",
      "Episode 2\tScore: 0.00\tRuntime: 33.38 sec\n",
      "Episode 3\tScore: 0.00\tRuntime: 49.98 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUMElEQVR4nO3df5BlZX3n8ffHGSQoCTCAiAxk2AU3C2sWyV2MUVNkUX4kS8ZNqGLU3Uyl3KKSiK6bylZQtuSH2Sq1kmhZmk0mQNXETfixGs1siCKCbkxUpIdMhCGBmQAGkISBQQzBgGO++8c5HS+dnunbT8+9d9p+v6pu9TnPefqeb595pj99znPvuakqJElarOdNuwBJ0vJkgEiSmhggkqQmBogkqYkBIklqsnraBUzSUUcdVevWrZt2GZK0rGzduvWxqjp6bvuKCpB169YxMzMz7TIkaVlJ8tX52r2EJUlqYoBIkpoYIJKkJgaIJKmJASJJamKASJKaGCCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqYkBIklqYoBIkpoYIJKkJgaIJKmJASJJamKASJKaGCCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqYkBIklqMtUASXJuknuS7ExyyTzbD05yfb/9tiTr5mw/IclTSX5pYkVLkoApBkiSVcCHgfOAU4A3JDllTrc3A09U1UnA+4H3ztn+68Anx12rJOmfm+YZyBnAzqq6r6qeBa4D1s/psx7Y3C9/FDgrSQCSvB64H9g+mXIlScOmGSDHAQ8OrT/Ut83bp6r2AE8CRyY5FPhl4IqFdpLkoiQzSWZ27dq1XwqXJC3fSfTLgfdX1VMLdayqTVU1qKrB0UcfPf7KJGmFWD3FfT8MHD+0vrZvm6/PQ0lWA4cBjwOvAC5I8j7gcOAfk/xDVX1o7FVLkoDpBsjtwMlJTqQLig3AG+f02QJsBL4IXADcWlUFvGa2Q5LLgacMD0marKkFSFXtSXIxcBOwCrimqrYnuRKYqaotwNXAR5LsBHbThYwk6QCQ7g/6lWEwGNTMzMy0y5CkZSXJ1qoazG1frpPokqQpM0AkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNphogSc5Nck+SnUkumWf7wUmu77fflmRd3/66JFuT3Nl//fcTL16SVripBUiSVcCHgfOAU4A3JDllTrc3A09U1UnA+4H39u2PAedX1cuAjcBHJlO1JGnWNM9AzgB2VtV9VfUscB2wfk6f9cDmfvmjwFlJUlV/VlVf69u3A4ckOXgiVUuSgOkGyHHAg0PrD/Vt8/apqj3Ak8CRc/r8NHBHVT0zpjolSfNYPe0CliLJqXSXtc7eR5+LgIsATjjhhAlVJknf/aZ5BvIwcPzQ+tq+bd4+SVYDhwGP9+trgY8DP1NVf7W3nVTVpqoaVNXg6KOP3o/lS9LKNs0AuR04OcmJSZ4PbAC2zOmzhW6SHOAC4NaqqiSHAzcCl1TVn06qYEnSd0wtQPo5jYuBm4C/AG6oqu1Jrkzyk323q4Ejk+wEfhGYfanvxcBJwLuSbOsfL5rwjyBJK1qqato1TMxgMKiZmZlplyFJy0qSrVU1mNvuO9ElSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1GTkAElySJJ/Nc5iJEnLx0gBkuR8YBvwqX79tCRbxliXJOkAN+oZyOXAGcDXAapqG3DiWCqSJC0LowbIt6rqyTlttb+LkSQtH6tH7Lc9yRuBVUlOBt4GfGF8ZUmSDnSjnoG8FTgVeAb4PeBJ4O1jqkmStAwseAaSZBVwY1X9GHDp+EuSJC0HC56BVNW3gX9MctgE6pEkLROjXsJ6CrgzydVJPjj7WOrOk5yb5J4kO5NcMs/2g5Nc32+/Lcm6oW3v6NvvSXLOUmuRJC3OqJPov98/9pv+0tiHgdcBDwG3J9lSVXcPdXsz8ERVnZRkA/Be4MIkpwAb6OZlXgJ8JslL+7MlSdIEjBQgVbU5yfOBl/ZN91TVt5a47zOAnVV1H0CS64D1wHCArKd7DwrAR4EPJUnffl1VPQPcn2Rn/3xfXGJN87ri/27n7q99YxxPLUljd8pLvo/Lzj91vz/vqO9EPxPYQXfG8BvAvUl+dIn7Pg54cGj9ob5t3j5VtYfu1V9Hjvi9s7VflGQmycyuXbuWWLIkadaol7B+DTi7qu4BSPJS4Frgh8ZV2P5SVZuATQCDwaDpzY/jSG5JWu5GnUQ/aDY8AKrqXuCgJe77YeD4ofW1fdu8fZKsBg4DHh/xeyVJYzRqgMwkuSrJmf3jt4GZJe77duDkJCf28ysbgLk3aNwCbOyXLwBurarq2zf0r9I6ETgZ+PIS65EkLcKol7B+HngL3S1MAD5PNxfSrKr2JLkYuAlYBVxTVduTXAnMVNUW4GrgI/0k+W66kKHvdwPdhPse4C2+AkuSJivdH/QLdEpeCPzD7C/p/iW4B1fV02Oub78aDAY1M7PUEydJWlmSbK2qwdz2US9h3QIcMrR+CPCZ/VGYJGl5GjVAvqeqnppd6ZdfMJ6SJEnLwagB8vdJTp9dSTIAvjmekiRJy8Gok+hvB/5Pkq/168cCF46lIknSsrDPM5Ak/y7Ji6vqduAHgOuBb9F9Nvr9E6hPknSAWugS1m8Bz/bLrwTeSXc7kyfo390tSVqZFrqEtaqqdvfLFwKbqupjwMeSbBtrZZKkA9pCZyCr+luIAJwF3Dq0bdT5E0nSd6GFQuBa4P8leYzuVVefB0hyEt2dcSVJK9Q+A6Sq/meSW+hedfXp+s7b1p8HvHXcxUmSDlwLXoaqqi/N03bveMqRJC0Xo76RUJKk5zBAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVKTqQRIkjVJbk6yo/96xF76bez77EiysW97QZIbk/xlku1J3jPZ6iVJML0zkEuAW6rqZOCWfv05kqwBLgNeAZwBXDYUNL9aVT8AvBx4VZLzJlO2JGnWtAJkPbC5X94MvH6ePucAN1fV7qp6ArgZOLeqnq6qzwJU1bPAHcDa8ZcsSRo2rQA5pqoe6Zf/Bjhmnj7HAQ8OrT/Ut/2TJIcD59OdxUiSJmj1uJ44yWeAF8+z6dLhlaqqJNXw/KuBa4EPVtV9++h3EXARwAknnLDY3UiS9mJsAVJVr93btiR/m+TYqnokybHAo/N0exg4c2h9LfC5ofVNwI6q+sACdWzq+zIYDBYdVJKk+U3rEtYWYGO/vBH4g3n63AScneSIfvL87L6NJL8CHAa8ffylSpLmM60AeQ/wuiQ7gNf26yQZJLkKoKp2A+8Gbu8fV1bV7iRr6S6DnQLckWRbkv8yjR9CklayVK2cqzqDwaBmZmamXYYkLStJtlbVYG6770SXJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSk6kESJI1SW5OsqP/esRe+m3s++xIsnGe7VuS3DX+iiVJc03rDOQS4JaqOhm4pV9/jiRrgMuAVwBnAJcNB02SnwKemky5kqS5phUg64HN/fJm4PXz9DkHuLmqdlfVE8DNwLkASQ4FfhH4lfGXKkmaz7QC5JiqeqRf/hvgmHn6HAc8OLT+UN8G8G7g14CnF9pRkouSzCSZ2bVr1xJKliQNWz2uJ07yGeDF82y6dHilqipJLeJ5TwP+ZVX9tyTrFupfVZuATQCDwWDk/UiS9m1sAVJVr93btiR/m+TYqnokybHAo/N0exg4c2h9LfA54JXAIMkDdPW/KMnnqupMJEkTM61LWFuA2VdVbQT+YJ4+NwFnJzminzw/G7ipqv5XVb2kqtYBrwbuNTwkafKmFSDvAV6XZAfw2n6dJIMkVwFU1W66uY7b+8eVfZsk6QCQqpUzLTAYDGpmZmbaZUjSspJka1UN5rb7TnRJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNUlXTrmFikuwCvtr47UcBj+3HcvYX61oc61oc61qc79a6vr+qjp7buKICZCmSzFTVYNp1zGVdi2Ndi2Ndi7PS6vISliSpiQEiSWpigIxu07QL2AvrWhzrWhzrWpwVVZdzIJKkJp6BSJKaGCCSpCYrPkCSXJPk0SR37WV7knwwyc4kX0ly+tC2jUl29I+NE67rTX09dyb5QpJ/O7Ttgb59W5KZCdd1ZpIn+31vS/KuoW3nJrmnP5aXTLiu/z5U011Jvp1kTb9tnMfr+CSfTXJ3ku1J/us8fSY+xkasa+JjbMS6Jj7GRqxr4mMsyfck+XKSP+/rumKePgcnub4/JrclWTe07R19+z1Jzll0AVW1oh/AjwKnA3ftZfuPA58EAvwwcFvfvga4r/96RL98xATr+pHZ/QHnzdbVrz8AHDWl43Um8IfztK8C/gr4F8DzgT8HTplUXXP6ng/cOqHjdSxwer/8vcC9c3/uaYyxEeua+Bgbsa6Jj7FR6prGGOvHzKH98kHAbcAPz+nzC8Bv9ssbgOv75VP6Y3QwcGJ/7FYtZv8r/gykqv4Y2L2PLuuB36nOl4DDkxwLnAPcXFW7q+oJ4Gbg3EnVVVVf6PcL8CVg7f7a91Lq2oczgJ1VdV9VPQtcR3dsp1HXG4Br99e+96WqHqmqO/rlvwP+AjhuTreJj7FR6prGGBvxeO3N2MZYQ10TGWP9mHmqXz2of8x9ZdR6YHO//FHgrCTp26+rqmeq6n5gJ90xHNmKD5ARHAc8OLT+UN+2t/ZpeDPdX7CzCvh0kq1JLppCPa/sT6k/meTUvu2AOF5JXkD3S/hjQ80TOV79pYOX0/2VOGyqY2wfdQ2b+BhboK6pjbGFjtekx1iSVUm2AY/S/cGx1/FVVXuAJ4Ej2Q/Ha3VjzTpAJPkxuv/crx5qfnVVPZzkRcDNSf6y/wt9Eu6gu2/OU0l+HPgEcPKE9j2K84E/rarhs5WxH68kh9L9Qnl7VX1jfz73UoxS1zTG2AJ1TW2MjfjvONExVlXfBk5Lcjjw8ST/pqrmnQvc3zwDWdjDwPFD62v7tr21T0ySHwSuAtZX1eOz7VX1cP/1UeDjLPK0dCmq6huzp9RV9UfAQUmO4gA4Xr0NzLm0MO7jleQgul86v1tVvz9Pl6mMsRHqmsoYW6iuaY2xUY5Xb+JjrH/urwOf5Z9f5vyn45JkNXAY8Dj743jt70md5fgA1rH3SeGf4LkTnF/u29cA99NNbh7RL6+ZYF0n0F2z/JE57S8Evndo+QvAuROs68V85w2qZwB/3R+71XSTwCfynQnOUydVV7/9MLp5khdO6nj1P/vvAB/YR5+Jj7ER65r4GBuxromPsVHqmsYYA44GDu+XDwE+D/yHOX3ewnMn0W/ol0/luZPo97HISfQVfwkrybV0r+o4KslDwGV0E1FU1W8Cf0T3KpmdwNPAz/bbdid5N3B7/1RX1nNPWcdd17vormP+Rjcfxp7q7rZ5DN1pLHT/oX6vqj41wbouAH4+yR7gm8CG6kbrniQXAzfRvVrmmqraPsG6AP4j8Omq+vuhbx3r8QJeBfxn4M7+OjXAO+l+OU9zjI1S1zTG2Ch1TWOMjVIXTH6MHQtsTrKK7orSDVX1h0muBGaqagtwNfCRJDvpwm1DX/P2JDcAdwN7gLdUdzlsZN7KRJLUxDkQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEGkF/Z9VtQ4993uk1yc8l+Zn9sN8H+jfJLfb7zklyRZI1ST658HdIi7fi3wcijeibVXXaqJ2H3hcwLa+he1fya4A/mXIt+i7lGYi0BP0Zwvv6z3r4cpKT+vbLk/xSv/y2dJ8j8ZUk1/Vta5J8om/7Un/LEJIcmeTT/Wc7XEX3DujZff2nfh/bkvxW/+axufVc2L/R7W3AB4DfBn42yZYxHwqtQAaINJpD5lzCunBo25NV9TLgQ3S/tOe6BHh5Vf0g8HN92xXAn/Vt76S7TQZ076D/k6o6le6eSScAJPnXwIXAq/ozoW8Db5q7o6q6nu5OsXf1Nd3Z7/sn2390aX5ewpJGs69LWNcOfX3/PNu/Avxukk/Q3TkWujvb/jRAVd3an3l8H90HY/1U335jktnP4zgL+CHg9v6WGIfQ3b57Pi+lu68RdPdk+ruFfjiphQEiLV3tZXnWT9AFw/nApUle1rCPAJur6h377NR9XOpRwOokdwPH9pe03lpVn2/Yr7RXXsKSlu7Coa9fHN6Q5HnA8VX1WeCX6e7WeijdXVPf1Pc5E3isus+X+GPgjX37eXR34QW4Bbig/zyJ2TmU759bSH+zwxvpPm3ufcClVXWa4aFx8AxEGs0hQ3dhBfhUVc2+lPeIJF8BnqH7KNNhq4D/neQwurOID1bV15NcDlzTf9/TwMa+/xXAtUm20932+68BquruJP+D7lPtngd8i+423V+dp9bT6SbRfwH49SX8zNI+eTdeaQmSPAAMquqxadciTZqXsCRJTTwDkSQ18QxEktTEAJEkNTFAJElNDBBJUhMDRJLU5P8DnqeaKUfxIc0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = ddpg(n_episodes=3)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception calling application: \n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\drlnd\\lib\\multiprocessing\\connection.py\", line 312, in _recv_bytes\n",
      "    nread, err = ov.GetOverlappedResult(True)\n",
      "BrokenPipeError: [WinError 109] 管道已结束。\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\envs\\drlnd\\lib\\site-packages\\grpc\\_server.py\", line 385, in _call_behavior\n",
      "    return behavior(argument, context), True\n",
      "  File \"D:\\anaconda3\\envs\\drlnd\\lib\\site-packages\\unityagents\\rpc_communicator.py\", line 26, in Exchange\n",
      "    return self.child_conn.recv()\n",
      "  File \"D:\\anaconda3\\envs\\drlnd\\lib\\multiprocessing\\connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "  File \"D:\\anaconda3\\envs\\drlnd\\lib\\multiprocessing\\connection.py\", line 321, in _recv_bytes\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
